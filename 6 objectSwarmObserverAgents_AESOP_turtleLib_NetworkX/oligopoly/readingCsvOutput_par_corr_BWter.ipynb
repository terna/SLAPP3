{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import matplotlib\n",
    "#matplotlib.style.use('ggplot') ## gnuplot style\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings as wn\n",
    "import partial_corr # found at \n",
    "                    # https://gist.github.com/fabianp/9396204419c7b638d38f\n",
    "\n",
    "\n",
    "#size\n",
    "width, height=12,8\n",
    "plt.rcParams['figure.figsize'] = width, height #aggiunta pt\n",
    "\n",
    "#precision in tables\n",
    "pd.set_option('precision',2)\n",
    "#rows in tables\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# this is used for regression below; install (via pip) statsmodels and patsy\n",
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# to chose a csv file in the current folder\n",
    "import os\n",
    "filesHere=os.listdir(\"./\")\n",
    "selected=[]\n",
    "for i in range(len(filesHere)):\n",
    "    if filesHere[i].find('_ts.csv')>0: selected.append(filesHere[i])\n",
    "selected.sort()\n",
    "for i in range(len(selected)):\n",
    "    print (i, selected[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num=int(input(\"Choose a file via its number (>=0;<=\"+str(len(selected)-1)+\" \"))\n",
    "\n",
    "try:\n",
    "    modPars_df = pd.read_csv(selected[num][:17]+'_modPars.csv')\n",
    "    modPars_df.index += 1 \n",
    "except BaseException:\n",
    "    modPars_df = pd.DataFrame([[\"no changes in parameters\"]],columns=[\"  \"])\n",
    "    modPars_df.index += 1\n",
    "\n",
    "firms=False\n",
    "    \n",
    "try:\n",
    "    firms_df = pd.read_csv(selected[num][:17]+'_firms.csv')\n",
    "    modPars_df.index += 1 \n",
    "    firms=True\n",
    "except BaseException:\n",
    "    pass\n",
    "\n",
    "\n",
    "par_df = pd.read_csv(selected[num][:17]+'_par.csv')\n",
    "par_df.index += 1 \n",
    "\n",
    "nameFilePar=selected[num][:17]+'_par.csv'\n",
    "\n",
    "ts_df = pd.read_csv(selected[num])\n",
    "#set index to start from 1, data are collected at the end of each period\n",
    "ts_df.index += 1 \n",
    "\n",
    "str_df = pd.read_csv(selected[num][:17]+'_str.csv')\n",
    "#leave index to start from 0, data are collected at the beginning of each period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select rows (time steps) in the database\n",
    "\n",
    "activating the cell below before running the whole program\n",
    "\n",
    "    [a:b] => from a+1 to b\n",
    "    \n",
    "    [:b]  => fron init to b\n",
    "    [a:]  => fron a+1 to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts_df =ts_df [0:45]\n",
    "#str_df=str_df[0:45]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Parameters***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "par_df.astype(str,errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modified parameters***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modPars_df.astype(str,errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Time series, data collected at the end of each period***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if len(ts_df.columns) == 6:\n",
    "    ts_df.columns = \\\n",
    "    ['unempl.','totalProfit','totalProd.','plannedP.','price','wage']\n",
    "    # to have shorter names\n",
    "if len(ts_df.columns) == 8:\n",
    "    ts_df.columns = \\\n",
    "    ['unempl.','totalProfit','totalProd.','plannedP.', 'cQ','hPSd','price','wage']\n",
    "    # to have shorter names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ts_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts_df.corr(method=\"pearson\").style.format(\"{:.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The origin of the partial_corr source is [https://gist.github.com/fabianp/9396204419c7b638d38f](https://gist.github.com/fabianp/9396204419c7b638d38f)\n",
    "\n",
    "At [http://en.wikipedia.org/wiki/Partial_correlation#Using_linear_regression](http://en.wikipedia.org/wiki/Partial_correlation#Using_linear_regression) we have the explanation of the need of augmenting the data matrix with a 1 to allow for a constant term in the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wn.filterwarnings(action=\"ignore\") # to eliminate a warning about \n",
    "                                   #LAPACK lib\n",
    "\n",
    "np.set_printoptions(precision=2,suppress=True)\n",
    "ts=ts_df.values\n",
    "ts_int = np.hstack((np.ones((ts.shape[0],1)), ts))\n",
    "\n",
    "out1=partial_corr.partial_corr(ts_int)[1:, 1:]\n",
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ts=ts_df.drop(columns=\"plannedP.\").values\n",
    "ts_int = np.hstack((np.ones((ts.shape[0],1)), ts))\n",
    "\n",
    "out2=partial_corr.partial_corr(ts_int)[1:, 1:]\n",
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ts=ts_df.drop(columns=\"totalProd.\").values\n",
    "ts_int = np.hstack((np.ones((ts.shape[0],1)), ts))\n",
    "\n",
    "out3=partial_corr.partial_corr(ts_int)[1:, 1:]\n",
    "out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ts2_df=ts_df\n",
    "if len(ts_df.columns) == 6:\n",
    "    ts2_df.columns = \\\n",
    "    ['unempl','totalProfit','totalProd','plannedP','price','wage']\n",
    "if len(ts_df.columns) == 8:\n",
    "    ts2_df.columns = \\\n",
    "    ['unempl','totalProfit','totalProd','plannedP','cQ','hPSd','price','wage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = sm.ols(formula=\"totalProfit ~ price + wage + totalProd + unempl\", \\\n",
    "                data=ts2_df).fit()\n",
    "\n",
    "print (result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Structural infos, data collected at the beginning of each period***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "str_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "levels of gray\n",
    "https://en.wikipedia.org/wiki/Shades_of_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "myPlot = ts_df.plot(figsize=(11,8),secondary_y=['hPriceSd', 'price','wage'],marker=\"*\",\n",
    "color=[\"OrangeRed\",\"LawnGreen\",\"Blue\",\"Violet\",\"lightblue\",\"Pink\",\"Gray\",\"Brown\"])\n",
    "myPlot.set_ylabel('unemployed, totalProfit, totalProduction, plannedProduction, consumptionQ')\n",
    "myPlot.right_ax.set_ylabel('hPriceSd, price, wage')\n",
    "myPlot.legend(loc='upper left') #, bbox_to_anchor=(-0.35, 0.5)\n",
    "myPlot.axes.right_ax.legend(loc='lower right') #, bbox_to_anchor=(1.1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "myPlot = ts_df.plot(figsize=(11,8),secondary_y=['hPriceSd', 'price','wage'],marker=\"\",\n",
    "color=[\"lightgray\",\"Black\",\"Black\",\"Black\",\"Gray\",\"lightgray\",\"lightgray\",\"lightgray\"],\n",
    "style=['-', '--', '-.', ':','-', '--', '-.'],\n",
    "linewidth=1.)\n",
    "myPlot.set_ylabel('unemployed, totalProfit, totalProduction, plannedProduction, consumptionQ')\n",
    "myPlot.right_ax.set_ylabel('hPriceSd, price, wage')\n",
    "myPlot.legend(loc='upper left') #, bbox_to_anchor=(-0.35, 0.5)\n",
    "myPlot.axes.right_ax.legend(loc='lower right') #, bbox_to_anchor=(1.1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "myPlot = ts_df.plot(figsize=(11,8),secondary_y=['hPriceSd', 'price','wage'],marker=\"\",\n",
    "color=[\"silver\",\"Black\",\"Black\",\"Black\",\"Gray\",\"slategray\",\"slategray\",\"slategray\"],\n",
    "style=['-', '--', '-.', ':','-', '--', '-.'],\n",
    "linewidth=2.)\n",
    "myPlot.set_ylabel('unemployed, totalProfit, totalProduction, plannedProduction, consumptionQ')\n",
    "myPlot.right_ax.set_ylabel('hPriceSd, price, wage')\n",
    "myPlot.legend(loc='upper left') #, bbox_to_anchor=(-0.35, 0.5)\n",
    "myPlot.axes.right_ax.legend(loc='lower right') #, bbox_to_anchor=(1.1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "str_df.plot(figsize=(11,8),secondary_y='workers',marker=\"*\",color=[\"r\",\"b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "str_df.plot(figsize=(11,8),secondary_y='workers',marker=\"*\",color=[\"black\",\n",
    "            \"lightgrey\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "str_df.plot(figsize=(11,8),linewidth=2.0,secondary_y='workers',marker=\"*\",color=[\"black\",\n",
    "            \"gray\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best solutions to produce a LaTeX table from these data (the example is related to ts_df.corr table):\n",
    "\n",
    "    corr=ts_df.corr(method='pearson')\n",
    "    print corr.to_latex()\n",
    "    \n",
    "    \"print\" to have the output nicely formatted; copy and paste it to LaTeX and the \n",
    "    result works.\n",
    "    \n",
    "To output is included within:\n",
    "\n",
    "    \\begin{table}[htbp]\n",
    "    \n",
    "    ... output above ...\n",
    "    \n",
    "    \\label{a label}\n",
    "    \\caption{a caption}\n",
    "    \\end{table}\n",
    "\n",
    "We add also size specifications (\\footnotesize in this case) and the usual [htbp] specification with \\begin{table}[htbp]\n",
    "\n",
    "\n",
    "Other solutions:\n",
    "1. online [http://www.tablesgenerator.com](http://www.tablesgenerator.com), reading the csv file;\n",
    "2. using a converter as [http://html2latex.sourceforge.net](http://html2latex.sourceforge.net).\n",
    "\n",
    "## The first method is applied in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr=ts_df.corr(method='pearson')\n",
    "def ff(x):\n",
    "    return '%1.2f' % x\n",
    "if len(ts_df.columns) == 6:\n",
    "    print (\"\\\\begin{table}[!htbp]\\n{\\\\footnotesize \\center\")\n",
    "if len(ts_df.columns) == 8:\n",
    "    print (\"\\\\begin{table}[!htbp]\\n{\\\\tiny \\center\")\n",
    "print (corr.to_latex(formatters=[ff,ff,ff,ff,ff,ff,ff,ff]))\n",
    "print(\"}\\n\\\\caption{Correlations among the time series of the model,\"+\\\n",
    "      \" with xxx}\")\n",
    "print(\"\\\\label{correlations xxx}\\n\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ou=out1\n",
    "if len(ts_df.columns) == 6:\n",
    "    names=['unempl.','totalProfit','totalProd.','plannedP.','price','wage']\n",
    "if len(ts_df.columns) == 8:\n",
    "    names=['unempl.','totalProfit','totalProd.','plannedP.','cQ','hPSd','price','wage']\n",
    "if len(ts_df.columns) == 6:\n",
    "    print (\"\\\\begin{table}[!htbp]\\n{\\\\footnotesize \\center\")\n",
    "if len(ts_df.columns) == 8:\n",
    "    print (\"\\\\begin{table}[!htbp]\\n{\\\\tiny \\center\")\n",
    "if len(ts_df.columns) == 6:\n",
    "        print (\"\\\\begin{tabular}{lrrrrrr}\\n\\\\toprule\\n\"+\\\n",
    "\"{} & unempl. & totalProfit & totalProd. & plannedP. & price &  wage \\\\\\\\\"+\\\n",
    "\"\\n\\\\midrule\")\n",
    "if len(ts_df.columns) == 8:\n",
    "        print (\"\\\\begin{tabular}{lrrrrrrrr}\\n\\\\toprule\\n\"+\\\n",
    "\"{} & unempl. & totalProfit & totalProd. & plannedP. & cQ & hPSd & price &  wage \\\\\\\\\"+\\\n",
    "\"\\n\\\\midrule\")\n",
    "for i in range(len(ou)):\n",
    "    print(names[i], end=\"\")\n",
    "    for j in range(len(ou[i])):\n",
    "        print(\" & %.2f\" % ou[i,j], end=\"\")\n",
    "    print(\" \\\\\\\\\")\n",
    "print(\"\\\\bottomrule\\n\\\\end{tabular}\")    \n",
    "print(\"}\\n\\\\caption{Partial correlations among the time series of the model,\"+\\\n",
    "      \" with xxx}\")\n",
    "print(\"\\\\label{partial correlations xxx}\\n\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ou=out2\n",
    "if len(ts_df.columns) == 6:\n",
    "    names=['unempl.','totalProfit','totalProd.','price','wage']\n",
    "if len(ts_df.columns) == 8:\n",
    "    names=['unempl.','totalProfit','totalProd.','cQ','hPSd','price','wage']\n",
    "print (\"\\\\begin{table}[!htbp]\\n{\\\\footnotesize \\center\")\n",
    "if len(ts_df.columns) == 6:\n",
    "        print (\"\\\\begin{tabular}{lrrrrr}\\n\\\\toprule\\n\"+\\\n",
    "\"{} & unempl. & totalProfit & totalProd. & price &  wage \\\\\\\\\"+\\\n",
    "\"\\n\\\\midrule\")\n",
    "if len(ts_df.columns) == 8:\n",
    "        print (\"\\\\begin{tabular}{lrrrrrrr}\\n\\\\toprule\\n\"+\\\n",
    "\"{} & unempl. & totalProfit & totalProd. & cQ & hPSd & price &  wage \\\\\\\\\"+\\\n",
    "\"\\n\\\\midrule\")\n",
    "for i in range(len(ou)):\n",
    "    print(names[i], end=\"\")\n",
    "    for j in range(len(ou[i])):\n",
    "        print(\" & %.2f\" % ou[i,j], end=\"\")\n",
    "    print(\" \\\\\\\\\")\n",
    "print(\"\\\\bottomrule\\n\\\\end{tabular}\")    \n",
    "print(\"}\\n\\\\caption{Partial correlations (no plannedProduction) among the time series of the model,\"+\\\n",
    "      \" with xxx}\")\n",
    "print(\"\\\\label{partial correlations (no plannedP.) xxx}\\n\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ou=out3\n",
    "if len(ts_df.columns) == 6:\n",
    "    names=['unempl.','totalProfit','plannedP.','price','wage']\n",
    "if len(ts_df.columns) == 8:\n",
    "    names=['unempl.','totalProfit','plannedP.','cQ','hPSd','price','wage']\n",
    "print (\"\\\\begin{table}[!htbp]\\n{\\\\footnotesize \\center\")\n",
    "if len(ts_df.columns) == 6:\n",
    "        print (\"\\\\begin{tabular}{lrrrrr}\\n\\\\toprule\\n\"+\\\n",
    "\"{} & unempl. & totalProfit & plannedP. & price &  wage \\\\\\\\\"+\\\n",
    "\"\\n\\\\midrule\")\n",
    "if len(ts_df.columns) == 8:\n",
    "        print (\"\\\\begin{tabular}{lrrrrrrr}\\n\\\\toprule\\n\"+\\\n",
    "\"{} & unempl. & totalProfit & plannedP. & cQ & hPSd & price &  wage \\\\\\\\\"+\\\n",
    "\"\\n\\\\midrule\")\n",
    "for i in range(len(ou)):\n",
    "    print(names[i], end=\"\")\n",
    "    for j in range(len(ou[i])):\n",
    "        print(\" & %.2f\" % ou[i,j], end=\"\")\n",
    "    print(\" \\\\\\\\\")\n",
    "print(\"\\\\bottomrule\\n\\\\end{tabular}\")    \n",
    "print(\"}\\n\\\\caption{Partial correlations (no totalProduction) among the time series of the model,\"+\\\n",
    "      \" with xxx}\")\n",
    "print(\"\\\\label{partial correlations (no totalProd.) xxx}\\n\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Data from each firm in each period*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if firms: print(firms_df.describe())\n",
    "else: print('no data for each firm in each period')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Managing parameter list*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctitle=\"\"\n",
    "if len(par_df.columns)==2: ctitle=par_df.columns[0]\n",
    "if len(par_df.columns)==3: ctitle=par_df.columns[1]\n",
    "if len(ts_df.columns) == 6:\n",
    "    parList=par_df[ctitle].tolist()\n",
    "    valList=par_df[\"Values\"].tolist()\n",
    "if len(ts_df.columns) == 8: \n",
    "    parList=par_df[\"Parameter internal names\"].tolist()\n",
    "    valList=par_df[\"Values\"].tolist()\n",
    "# both parList are generated by the 'print' of parameters.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dictionay of values**\n",
    "\n",
    "***d_val***\n",
    "\n",
    "it comes from the file \\*_par.csv coming from the 'print' of parameters.py\n",
    "\n",
    "**NB** the different versions of the model have different parameters output sequences; the main difference is about the 6 time series case and the 8 time series case in file \\*_ts.csv, emerging above\n",
    "\n",
    "\\[zip() function take iterables (can be zero or more), makes \n",
    "iterator that aggregates elements based on the iterables passed, \n",
    "and returns an iterator of tuples. zip() function take iterables \n",
    "(can be zero or more), makes iterator that aggregates elements \n",
    "based on the iterables passed, and returns an iterator of tuples\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_val=dict(zip(parList,valList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dictionay of position**\n",
    "\n",
    "***d_pos***\n",
    "\n",
    "the dict of positions (file parPos.csv) comes from a manual work based on the table of parameter definition of appendix B of the book; the goal is that of retrieving the parameters of a specific experiment in dict d_val and assign their values to the correct position in the rows of the table of the values in the different experiments in the parameter value table of Appendix B\n",
    "\n",
    "the vector (row) is pre-filled with '-' signs as values not existent in the specific experiment\n",
    "\n",
    "the case of the par 'checkResConsUnsoldProd' is handled in a special way: \n",
    "the parameter 'checkResConsUnsoldProd' (not affecting the model, but only working on its output) appears 20180829 in 28ter experiment; in the first commit, of 20180830, the name is checkResCons, but quite immediately became checkResConsUnsoldProd; the commit of 20181013 signals the we have the output from parameters.py (the experiment 80 is of 20181009, so without that output); all the experiments from 28ter to 80 have implicitly 'checkResConsUnsoldProd' set to True\n",
    "\n",
    "'w' case is corrected to 'Q'\n",
    "\n",
    "to check for the consistence of the dictionaries, we list unfound parameters in ***d_val*** when searching for values (the master dict is ***d_pos***)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsPositions_df= pd.read_csv('labelsPositions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labelsPositions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parList2=labelsPositions_df[\"name\"].tolist()\n",
    "posList=labelsPositions_df[\"position\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pos=dict(zip(parList2,posList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row=['-']*53 # 52 parameters, pos. 0 is used for unuseful values\n",
    "row[44]='51' # as default value for the par 'startHayekianMarket' for old\n",
    "             # SMAC versions where it was not defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(len(parList)):\n",
    "    if parList[_]=='w': row[d_pos['Q']]=d_val[parList[_]]\n",
    "    if parList[_] in d_pos: row[d_pos[parList[_]]]=d_val[parList[_]]\n",
    "    else: print('not found:',parList[_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the parameter checkResConsUnsoldProd (not affecting the model, but only working on its output) appears 20180829 in 28ter experiment; in the first commit, of 20180830, the name is checkResCons, but quite immediately became checkResConsUnsoldProd; the commit of 20181013 signals the we have the output from parameters.py (the experiment 80 is of 20181009, so without that output); all the experiments from 28ter to 80 have internally checkResConsUnsoldProd set to True\n",
    "\n",
    "so from >= 20180829 to <= 20181009 the val of checkResConsUnsoldProd is True\n",
    "\n",
    "1535414400 is equivalent to 08/28/2018 @ 12:00am (UTC)\n",
    "1539129600 is equivalent to 10/10/2018 @ 12:00am (UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "def creation_date(path_to_file):\n",
    "    \"\"\"\n",
    "    Try to get the date that a file was created, falling back to when it was\n",
    "    last modified if that isn't possible.\n",
    "    See http://stackoverflow.com/a/39501288/1709587 for explanation.\n",
    "    \"\"\"\n",
    "    if platform.system() == 'Windows':\n",
    "        return os.path.getctime(path_to_file)\n",
    "    else: #MacOs\n",
    "        stat = os.stat(path_to_file)\n",
    "        try:\n",
    "            return stat.st_birthtime\n",
    "        except AttributeError:\n",
    "            # We're probably on Linux. No easy way to get creation dates here,\n",
    "            # so we'll settle for when its content was last modified.\n",
    "            return stat.st_mtime\n",
    "        \n",
    "#converter https://www.unixtimestamp.com\n",
    "        \n",
    "fileTime=creation_date(\"./\"+nameFilePar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fileTime >= 1535414400 and fileTime <= 1539129600:\n",
    "    row[8]='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(1,len(row)-1):\n",
    "#    print(row[i],\"& \",end='')\n",
    "#print(row[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,26):\n",
    "    print(row[i],\"& \",end='')\n",
    "print(row[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(27,len(row)-1):\n",
    "    print(row[i],\"& \",end='')\n",
    "if '[' in row[-1]: row[-1]=row[-1][1:5] # [1:5] is to avoid the [ ] output\n",
    "print(row[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
